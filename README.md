# DO DEEP GENERATIVE MODELS KNOW WHAT THEY DONâ€™T KNOW? - A reproduction study

## Introduction
In their paper, Nalisnick et al. challenge the common understanding of generative model's robustness to different distribution data. Many types of neural networks have shown that their confidence on other distributions can be very high, mispredicting outcomes with a high confidence. It was believed that this was not an issue for deep generative models, however Nalisnick et al. demonstrate that this phenomena can be observed in 

## Reproduction of data analysis

## Further inspection of data

### Non-normal distributions

### Reduced space representation 

#### Principal component analysis (PCA)

#### Discriminant representation

#### Autoencoder representation
